{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import sklearn\n",
    "#poly=sklearn.preprocessing.PolynomialFeatures(interaction_only=True,include_bias = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = pd.read_csv('Retail_Train-1553348772483.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = mydata.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.PersonID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata[\"FamilySize\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata[\"TransactionMode\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata[\"Occupation\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata[\"TransactionMode\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mydata.Amount,bins=10)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Amount Distribution',pad=10)\n",
    "plt.xlabel('Amount',labelpad=10)\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[0,2,5,9]\n",
    "mydata['Famsize'] = pd.cut(mydata['Famsize'],bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['Famsize'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['Occupation'] = mydata['Occupation'].astype('category')\n",
    "mydata['TransactionMode'] = mydata['TransactionMode'].astype('category')\n",
    "mydata['Area'] = mydata['Area'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping Columns family size and Person ID\n",
    "mydata = mydata.drop(columns=['PersonID','FamilySize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Null Values\n",
    "mydata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356      8\n",
       "316      7\n",
       "226      7\n",
       "419      7\n",
       "321      7\n",
       "803      7\n",
       "481      7\n",
       "86       6\n",
       "741      6\n",
       "173      6\n",
       "1969     6\n",
       "236      6\n",
       "568      6\n",
       "1033     6\n",
       "106      6\n",
       "1179     5\n",
       "241      5\n",
       "369      5\n",
       "662      5\n",
       "511      5\n",
       "778      5\n",
       "901      5\n",
       "454      5\n",
       "30       5\n",
       "133      5\n",
       "218      5\n",
       "1340     5\n",
       "1367     5\n",
       "266      5\n",
       "1767     5\n",
       "        ..\n",
       "2336     1\n",
       "4385     1\n",
       "2338     1\n",
       "293      1\n",
       "2342     1\n",
       "2348     1\n",
       "2352     1\n",
       "305      1\n",
       "307      1\n",
       "10502    1\n",
       "2308     1\n",
       "253      1\n",
       "215      1\n",
       "2240     1\n",
       "4289     1\n",
       "195      1\n",
       "2248     1\n",
       "2252     1\n",
       "207      1\n",
       "2258     1\n",
       "2264     1\n",
       "2296     1\n",
       "217      1\n",
       "2266     1\n",
       "219      1\n",
       "6378     1\n",
       "449      1\n",
       "2292     1\n",
       "4898     1\n",
       "4059     1\n",
       "Length: 1749, dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(mydata['Quantity'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata= mydata[~(mydata == 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(mydata['Quantity'].values,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mydata['DirectVisits']>mydata['OnlineVisits']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mydata['DirectVisits']==0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mydata['OnlineVisits']==0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=mydata['DirectVisits'] - mydata['OnlineVisits']\n",
    "x\n",
    "(x==mydata['OnlineVisits']).value_counts()\n",
    "##Only online only users which is not very significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.plot(x='DirectVisits',y='OnlineVisits',style=['o','rx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= mydata['Amount']\n",
    "X=mydata[mydata.columns.difference(['Amount'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribute = X.select_dtypes(include='number').columns.tolist()\n",
    "cat_attributes = X.columns.difference(num_attribute).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standardizer = StandardScaler()\n",
    "standardizer.fit(X[num_attribute])\n",
    "X[num_attribute] = standardizer.transform(X[num_attribute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split ##X stands for data Y stands for y variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train',X_train.shape)\n",
    "print('y_train',y_train.shape)\n",
    "print('X_test',X_test.shape)\n",
    "\n",
    "print('y_test',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "## Model building\n",
    "regressor = linear_model.LinearRegression()\n",
    "\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "y_pred_train = regressor.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_test, y_pred): \n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients: \\n', regressor.coef_)\n",
    "## Train Error\n",
    "print(\"Mean absolute percentage error - Train: %.2f\"\n",
    "      % mean_absolute_percentage_error(y_train, y_pred_train))\n",
    "# The mean squared error\n",
    "print(\"Mean absolute percentage error: %.2f\"\n",
    "      % mean_absolute_percentage_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sfm\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif[\"features\"] = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model2 building another model after dropping columns which have high colinearity\n",
    "X_train2 = X_train.drop(columns=['Famsize_(0, 2]','Famsize_(2, 5]'])\n",
    "X_test2 = X_test.drop(columns=['Famsize_(0, 2]','Famsize_(2, 5]'])\n",
    "print(X_train2.shape)\n",
    "print(X_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor2 = linear_model.LinearRegression()\n",
    "regressor2.fit(X_train2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = regressor2.predict(X_test2)\n",
    "y_pred_train2 = regressor2.predict(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients: \\n', regressor2.coef_)\n",
    "## Train Error\n",
    "print(\"Mean absolute percentage error - Train: %.2f\"\n",
    "      % mean_absolute_percentage_error(y_train, y_pred_train2))\n",
    "# The mean squared error\n",
    "print(\"Mean absolute percentage error: %.2f\"\n",
    "      % mean_absolute_percentage_error(y_test, y_pred2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying OLS regression for model3\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = sm.OLS(y_train,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = model3.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## building model with ccolumns which have p value <0.5\n",
    "X_train4 = X_train.drop(columns=['DirectVisits', 'NumberofFrequentItems','OnlineVisits','Area_Area1','Area_Area2','Occupation_1','Occupation_2', 'Occupation_3', 'TransactionMode_1','TransactionMode_2'])\n",
    "X_test4 = X_test.drop(columns=['DirectVisits', 'NumberofFrequentItems','OnlineVisits','Area_Area1','Area_Area2','Occupation_1','Occupation_2', 'Occupation_3', 'TransactionMode_1','TransactionMode_2'])\n",
    "\n",
    "print(X_train4.shape)\n",
    "print(X_test4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = sm.OLS(y_train,X_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = model4.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model details so far\n",
    "print(\"Model1 - Linear Model\")\n",
    "## Train Error\n",
    "print(\"Mean absolute percentage error - Train: %.2f\"\n",
    "      % mean_absolute_percentage_error(y_train, y_pred_train))\n",
    "# The mean squared error\n",
    "print(\"Mean absolute percentage error: %.2f\"\n",
    "      % mean_absolute_percentage_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "print(\"________________________________________________________________________\")\n",
    "\n",
    "\n",
    "## Model details so far\n",
    "print(\"Model2 - Linear Model reduced dimensions after colinearity check\")\n",
    "## Train Error\n",
    "print(\"Mean absolute percentage error - Train: %.2f\"\n",
    "      % mean_absolute_percentage_error(y_train, y_pred_train2))\n",
    "# The mean squared error\n",
    "print(\"Mean absolute percentage error: %.2f\"\n",
    "      % mean_absolute_percentage_error(y_test, y_pred2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred2))\n",
    "print(\"________________________________________________________________________\")\n",
    "\n",
    "\n",
    "\n",
    "## Model 3\n",
    "print(\"Model 3 - OLS Regression\")\n",
    "error3 = math.sqrt(result3.mse_model)\n",
    "print(\"Mean squared error: \",error3)\n",
    "print('R-Square Score: ', result3.rsquared)\n",
    "print(\"________________________________________________________________________\")\n",
    "\n",
    "import math\n",
    "## Model 4\n",
    "\n",
    "print(\"Model 4 - OLS Regression after Dimensionality reduction\")\n",
    "\n",
    "error4 = math.sqrt(result4.mse_model)\n",
    "print(\"Mean squared error:\",error4)\n",
    "print(\"R-Square Score:\",result4.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "lasso.fit(X_train,y_train)\n",
    "train_score=lasso.score(X_train,y_train)\n",
    "test_score=lasso.score(X_test,y_test)\n",
    "coeff_used = np.sum(lasso.coef_!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training score:\", train_score)\n",
    "print (\"test score: \", test_score)\n",
    "print (\"number of features used: \", coeff_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso001 = Lasso(alpha=0.01, max_iter=10e5)\n",
    "lasso001.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score001=lasso001.score(X_train,y_train)\n",
    "test_score001=lasso001.score(X_test,y_test)\n",
    "coeff_used001 = np.sum(lasso001.coef_!=0)\n",
    "print (\"training score for alpha=0.01:\", train_score001) \n",
    "print (\"test score for alpha =0.01: \", test_score001)\n",
    "print (\"number of features used: for alpha =0.01:\", coeff_used001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso00001 = Lasso(alpha=0.0001, max_iter=10e5)\n",
    "lasso00001.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score00001=lasso00001.score(X_train,y_train)\n",
    "test_score00001=lasso00001.score(X_test,y_test)\n",
    "coeff_used00001 = np.sum(lasso00001.coef_!=0)\n",
    "print (\"training score for alpha=0.0001:\", train_score00001) \n",
    "print (\"test score for alpha =0.0001: \", test_score00001)\n",
    "print (\"number of features used: for alpha =0.0001:\", coeff_used00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,2)\n",
    "plt.plot(lasso.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Lasso; $\\alpha = 1$',zorder=7) # alpha here is for transparency\n",
    "plt.plot(lasso001.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'Lasso; $\\alpha = 0.01$') # alpha here is for transparency\n",
    "plt.plot(lasso00001.coef_,alpha=0.8,linestyle='none',marker='v',markersize=6,color='black',label=r'Lasso; $\\alpha = 0.00001$') # alpha here is for transparency\n",
    "plt.plot(regressor.coef_,alpha=0.7,linestyle='none',marker='o',markersize=5,color='green',label='Linear Regression',zorder=2)\n",
    "plt.xlabel('Coefficient Index',fontsize=16)\n",
    "plt.ylabel('Coefficient Magnitude',fontsize=16)\n",
    "plt.legend(fontsize=13,loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trying SVM regressor on the data\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "## Create an SVC object and print it to see the default arguments\n",
    "svr = SVR()\n",
    "svr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "svr_rbf = SVR(kernel= 'rbf', C= 1e3, gamma= 0.1) # defining the support vector regression models\n",
    "svr_lin = SVR(kernel= 'linear', C= 1e3)\n",
    "svr_poly = SVR(kernel= 'poly', C= 1e3, degree= 2)\n",
    "svr_rbf.fit(X_train, y_train) # fitting the data points in the models\n",
    "svr_lin.fit(X_train, y_train)\n",
    "svr_poly.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plt.scatter(X_train, y_train, color= 'black', label= 'Data') # plotting the initial datapoints \n",
    "plt.plot(X_train, svr_rbf.predict(X_train), color= 'red', label= 'RBF model') # plotting the line made by the RBF kernel\n",
    "plt.plot(X_train,svr_lin.predict(X_train), color= 'green', label= 'Linear model') # plotting the line made by linear kernel\n",
    "plt.plot(X_train,svr_poly.predict(X_train), color= 'blue', label= 'Polynomial model') # plotting the line made by polynomial kernel\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Support Vector Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressortree1 = DecisionTreeRegressor(max_depth=5)\n",
    "regressortree2 = DecisionTreeRegressor(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressortree1.fit(X_train, y_train)\n",
    "regressortree2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tree1 = regressortree1.predict(X_test)\n",
    "y_pred_tree2 = regressortree2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_test, y_pred_tree1, color=\"cornflowerblue\",\n",
    "         label=\"max_depth=2\", linewidth=2)\n",
    "plt.plot(y_test, y_pred_tree2, color=\"yellowgreen\", label=\"max_depth=5\", linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Tree 1\")\n",
    "print(\"_____________________________\")\n",
    "print('Train score:',regressortree1.score(X_train,y_train))\n",
    "print('Test score:',regressortree1.score(X_test,y_test))\n",
    "\n",
    "print(\"Tree 2\")\n",
    "print(\"_____________________________\")\n",
    "print('Train score:',regressortree2.score(X_train,y_train))\n",
    "\n",
    "print('Test Score:', regressortree2.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressortree1.feature_importances_\n",
    "## Get important Features\n",
    "fi_dt1 = pd.Series(regressortree1.feature_importances_, index = X_train.columns)\n",
    "fi_dt1_ordered = feat_importances.nlargest(n=len(fi_dt1))\n",
    "%matplotlib notebook\n",
    "feat_importances_ordered.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressortree2.feature_importances_\n",
    "## Get important Features\n",
    "fi_dt2 = pd.Series(regressortree2.feature_importances_, index = X_train.columns)\n",
    "fi_dt2_ordered = feat_importances.nlargest(n=len(fi_dt2))\n",
    "%matplotlib notebook\n",
    "feat_importances_ordered.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Model initilization\n",
    "rfc1 = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=0, oob_score=True)\n",
    "# Model training\n",
    "rfc1.fit(X = X_train,y = y_train)\n",
    "\n",
    "# Model predictions\n",
    "rfc1_train_pred = rfc1.predict(X_train)\n",
    "rfc1_test_pred = rfc1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"Train Score:\", rfc1.score)\n",
    "print(\"OOB Score\", rfc1.oob_score_)\n",
    "\n",
    "print(\"Test Score:\",rfc1.base_estimator)\n",
    "##print(accuracy_score(y_test,rfc1_test_pred))\n",
    "##print(confusion_matrix(y_test,rfc1_test_pred))\n",
    "##print(classification_report(y_test,rfc1_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc1.feature_importances_\n",
    "## Get important Features\n",
    "feat_importances = pd.Series(rfc1.feature_importances_, index = X_train.columns)\n",
    "feat_importances_ordered = feat_importances.nlargest(n=len(feat_importances))\n",
    "%matplotlib notebook\n",
    "feat_importances_ordered.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basis this plot building a model based on the feature importance given by the tree\n",
    "X_train_f = X_train.drop(columns=['Area_Area1','Area_Area2','Occupation_1','Occupation_2', 'Occupation_3', 'TransactionMode_1','TransactionMode_2'])\n",
    "X_test_f = X_test.drop(columns=['Area_Area1','Area_Area2','Occupation_1','Occupation_2', 'Occupation_3', 'TransactionMode_1','TransactionMode_2'])\n",
    "reg_f = linear_model.LinearRegression()\n",
    "reg_f.fit(X_train_f,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_f = reg_f.predict(X_test_f)\n",
    "y_pred_train_f = reg_f.predict(X_train_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_f.shape)\n",
    "print(X_train_f.shape)\n",
    "\n",
    "\n",
    "print(y_test.shape)\n",
    "print(y_pred_f.shape)\n",
    "print(y_pred_train_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients: \\n', reg_f.coef_)\n",
    "## Train Error\n",
    "print(\"Mean absolute percentage error - Train: %.2f\"\n",
    "      % mean_absolute_percentage_error(y_train, y_pred_train_f))\n",
    "# The mean squared error\n",
    "print(\"Mean absolute percentage error - Test: %.2f\"\n",
    "      % mean_absolute_percentage_error(y_test, y_pred_f))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
